{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas to handle the files.\n",
    "#First read the list file and converting them to a list of dataframes using \n",
    "#Add them all into one big frame using concat\n",
    "corpus=['amazon_cells_labelled.txt',\"imdb_labelled.txt\",\"yelp_labelled.txt\"]\n",
    "data = pd.concat(pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col= None, header = 0 )\n",
    "for file in corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalised form of NaiveBayes Classifier\n",
    "#Training\n",
    "def NaiveBayes_A():\n",
    "    #noramalisation\n",
    "    stop_words =set(stopwords.words(\"english\"))\n",
    "    \n",
    "    #In order to count the word count per text it is easier to use Term Frequency Inverse Document Frequency\n",
    "    #Tfid transforms text to feature vecors,\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, strip_accents ='ascii', stop_words = stop_words, lowercase=True)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= vectorizer.fit_transform(data.Text) #Converting the dataframes in the data into features.\n",
    "    \n",
    "    #splitting our data into training and test sets\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 35 , train_size =0.95, test_size =0.05)\n",
    "    \n",
    "    #Training the Classifier (MultinomialNB Normalised Classifier(MNBN Classifier))\n",
    "    MNBN_classifier = naive_bayes.MultinomialNB()\n",
    "    model = MNBN_classifier.fit(x_train, y_train)\n",
    "   \n",
    "\n",
    "    return MNBN_classifier , vectorizer, model, x_test, y_test\n",
    "    \n",
    "#NaiveBayes_A()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NORMALISED NAIVE BAIYES CLASSIFIER\n",
    "def testNaiveBayes_A(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "    #Training on the normalised nb classifier\n",
    "    MNBN_classifier , vectorizer, model, x_test, y_test = NaiveBayes_A()\n",
    "    \n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "\n",
    "\n",
    "    #Making sentiment classification\n",
    "    predictL =[]\n",
    "    for i in range (len(x)):\n",
    "        sentiment = np.array([str(x[i])])\n",
    "        sentiment_transform = vectorizer.transform(sentiment)\n",
    "        predict =   MNBN_classifier.predict(sentiment_transform)\n",
    "        predictL.append(predict[0])\n",
    "\n",
    "        \n",
    "   #Evaluating the model using the classification report function form sklearn\n",
    "\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" ,accuracy_score(y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier was evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    \n",
    "    return(predictL,\"\\n\")\n",
    "#testNaiveBayes_A(\"yelp_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnNormalised form of NaiveBayes Classifier\n",
    "#Training\n",
    "def NaiveBayes_B():\n",
    "\n",
    "    #In order to count the word count per text it is easier to use Term Frequency Inverse Document Frequency\n",
    "    #Tfid transforms text to feature vecors,\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, strip_accents =None, lowercase=False)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= vectorizer.fit_transform(data.Text) #Converting the dataframes in the data into features.\n",
    "    \n",
    "    #splitting our data into training and test sets\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 35 , train_size =0.95, test_size =0.05)\n",
    "    \n",
    " #Training the Classifier (MultinomialNB Unormalised Classifier(MNBU Classifier))\n",
    "\n",
    "    MNBU_classifier = naive_bayes.MultinomialNB()\n",
    "    model= MNBU_classifier.fit(x_train, y_train)\n",
    "   \n",
    "\n",
    "    return MNBU_classifier , vectorizer, model, x_test,y_test\n",
    "    \n",
    "#NaiveBayes_B()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRAINING THE UNNORMALISED NAIVE BAIYES CLASSIFIER\n",
    "def testNaiveBayes_B(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "      #Training on the unnormalised nb classifier\n",
    "    MNBU_classifier  , vectorizer, model, x_test, y_test = NaiveBayes_B()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "    \n",
    "    #Making sentiment classification\n",
    "    predictL =[]\n",
    "    for i in range (len(x)):\n",
    "        sentiment = np.array([str(x[i])])\n",
    "        sentiment_transform = vectorizer.transform(sentiment)\n",
    "        predict =   MNBU_classifier.predict(sentiment_transform)\n",
    "        predictL.append(predict[0])\n",
    "        \n",
    "    \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    #print(\" Accuracy is: \" ,accuracy_score(y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    return(predictL,\"\\n\")\n",
    "    \n",
    "    \n",
    "#testNaiveBayes_B(\"yelp_labelled.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A NORMALISED LOGISTIC REGRESSION TRAIN FUNCTION.\n",
    "def normLR_A():\n",
    "    #noramalisation\n",
    "    stop_words =set(stopwords.words(\"english\"))\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, strip_accents ='ascii', stop_words = stop_words, lowercase=True)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "     \n",
    "    y = data.Label\n",
    "    x=vectorizer.fit_transform(data.Text)# transfroming the data to features \n",
    "    \n",
    "    #Removing unnecessary punctuations\n",
    "    df['Text'] = df.Text.str.replace('[^\\w\\s]', '') \n",
    " \n",
    "    #Training the data\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 40, train_size =0.95, test_size =0.05)\n",
    "   \n",
    "    #Training the Classifier (Logistic Regression Normalised Classifier(LRN))\n",
    "    LRN_classifier = LogisticRegression()\n",
    "    model = LRN_classifier.fit(x_train, y_train)\n",
    "        \n",
    "    return LRN_classifier, vectorizer, model, x_test, y_test\n",
    "#normLR_A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NORMALISED LOGISTIC REGRESSION CLASSIFIER\n",
    "def testNormLR_A(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "      #Training on the normalised LR classifier\n",
    "    LRN_classifier , vectorizer, model, x_test, y_test = normLR_A()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "\n",
    "    #Making sentiment classification\n",
    "    predictL =[]\n",
    "    for i in range (len(x)):\n",
    "        sentiment = np.array([str(x[i])])\n",
    "        sentiment_transform = vectorizer.transform(sentiment)\n",
    "        predict =  LRN_classifier .predict(sentiment_transform)\n",
    "        predictL.append(predict[0])\n",
    "        \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" , accuracy_score (y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    return(predictL,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A-Sackey\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
       "         vocabulary=None),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " <138x5883 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1631 stored elements in Compressed Sparse Row format>,\n",
       " 810    1\n",
       " 688    1\n",
       " 993    0\n",
       " 480    1\n",
       " 956    0\n",
       " 593    1\n",
       " 996    0\n",
       " 34     0\n",
       " 328    0\n",
       " 67     0\n",
       " 644    0\n",
       " 243    0\n",
       " 374    0\n",
       " 578    1\n",
       " 711    1\n",
       " 468    1\n",
       " 10     1\n",
       " 689    1\n",
       " 142    0\n",
       " 556    1\n",
       " 337    0\n",
       " 192    0\n",
       " 746    1\n",
       " 717    1\n",
       " 964    0\n",
       " 229    1\n",
       " 174    1\n",
       " 605    1\n",
       " 817    0\n",
       " 259    0\n",
       "       ..\n",
       " 551    1\n",
       " 517    1\n",
       " 932    0\n",
       " 322    0\n",
       " 272    1\n",
       " 448    0\n",
       " 628    1\n",
       " 914    0\n",
       " 42     0\n",
       " 695    1\n",
       " 638    0\n",
       " 36     1\n",
       " 804    0\n",
       " 395    0\n",
       " 988    0\n",
       " 119    0\n",
       " 401    1\n",
       " 121    1\n",
       " 571    1\n",
       " 180    0\n",
       " 209    0\n",
       " 794    1\n",
       " 765    1\n",
       " 410    1\n",
       " 836    0\n",
       " 443    1\n",
       " 148    0\n",
       " 144    1\n",
       " 159    1\n",
       " 963    0\n",
       " Name: Label, Length: 138, dtype: int64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AN UNNORMALISED  LOGISTIC REGRESSION TRAIN FUNCTION.\n",
    "def unNormLR_B():\n",
    "    \n",
    "    #making an unnormalised form of our classifier y removing stop words, and not performing any form of normalisation\n",
    "    UnNormalisedVectorizer = TfidfVectorizer(use_idf=False, strip_accents=None, lowercase=False )\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= UnNormalisedVectorizer.fit_transform(data.Text)# transfroming the data to features \n",
    "    \n",
    "    #Training the data\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 40, train_size =0.95, test_size =0.05)\n",
    "    \n",
    "    #Training the Classifier ( UnNormalised Logistic Regression Classifier)\n",
    "    UnNormalisedLr_classifier =LogisticRegression()\n",
    "    model = UnNormalisedLr_classifier.fit(x_train, y_train)\n",
    "    \n",
    "            \n",
    "    return UnNormalisedLr_classifier, UnNormalisedVectorizer, model, x_test, y_test\n",
    "unNormLR_B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text  Label\n",
      "0   I was disgusted because I was pretty sure that...    NaN\n",
      "1   I was shocked because no signs indicate cash o...    NaN\n",
      "2                                 Highly recommended.    NaN\n",
      "3              Waitress was a little slow in service.    NaN\n",
      "4   This place is not worth your time, let alone V...    NaN\n",
      "5                                did not like at all.    NaN\n",
      "6                                 The Burrittos Blah!    NaN\n",
      "7                                  The food, amazing.    NaN\n",
      "8                               Service is also cute.    NaN\n",
      "9   I could care less... The interior is just beau...    NaN\n",
      "10                                 So they performed.    NaN\n",
      "11  That's right....the red velvet cake.....ohhh t...    NaN\n",
      "12         - They never brought a salad we asked for.    NaN\n",
      "13  This hole in the wall has great Mexican street...    NaN\n",
      "14  Took an hour to get our food only 4 tables in ...    NaN\n",
      "15                  The worst was the salmon sashimi.    NaN\n",
      "16  Also there are combos like a burger, fries, an...    NaN\n",
      "17                      This was like the final blow!    NaN\n",
      "18  I found this place by accident and I could not...    NaN\n",
      "19  seems like a good quick place to grab a bite o...    NaN\n",
      "20                  Overall, I like this place a lot.    NaN\n",
      "21  The only redeeming quality of the restaurant w...    NaN\n",
      "22                    Ample portions and good prices.    NaN\n",
      "23  Poor service, the waiter made me feel like I w...    NaN\n",
      "24              My first visit to Hiro was a delight!    NaN\n",
      "25                                     Service sucks.    NaN\n",
      "26                       The shrimp tender and moist.    NaN\n",
      "27  There is not a deal good enough that would dra...    NaN\n",
      "28  Hard to judge whether these sides were good be...    NaN\n",
      "29  On a positive note, our server was very attent...    NaN\n",
      "30  Frozen pucks of disgust, with some of the wors...    NaN\n",
      "31  The only thing I did like was the prime rib an...    NaN\n",
      "32          It's too bad the food is so damn generic.    NaN\n",
      "33        The burger is good beef, cooked just right.    NaN\n",
      "34  If you want a sandwich just go to any Firehous...    NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A-Sackey\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Accuracy is:  73.18840579710145\n",
      " Accuracy is:  73.18840579710145\n",
      " Below is how the classifier is evaluated: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71        64\n",
      "           1       0.75      0.74      0.75        74\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       138\n",
      "   macro avg       0.73      0.73      0.73       138\n",
      "weighted avg       0.73      0.73      0.73       138\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " '\\n')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAINING THE NORMALISED LOGISTIC REGRESSION CLASSIFIER\n",
    "def testUnNormLR_B(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    print(df)\n",
    "    \n",
    "    #Training on the normalised LR classifier\n",
    "    UnNormalisedLr_classifier, vectorizer, model, x_test, y_test = unNormLR_B()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "    \n",
    "    #Making sentiment classification\n",
    "    predictL =[]\n",
    "    for i in range (len(x)):\n",
    "        sentiment = np.array([str(x[i])])\n",
    "        sentiment_transform = vectorizer.transform(sentiment)\n",
    "        predict = UnNormalisedLr_classifier.predict(sentiment_transform)\n",
    "        predictL.append(predict[0])\n",
    "        \n",
    "        \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    \n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" , accuracy_score (y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "\n",
    "    return(predictL,\"\\n\")\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "testUnNormLR_B(\"testing.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(classifier, version, predictL):\n",
    "    file_name = open(\"results-\"+classifier+\"-\"+version+\".txt\", w)\n",
    "    file_name.write(\"Ouput: \"+\"\\n\")\n",
    "    \n",
    "    for label in predictL:\n",
    "        file_name.write(str(label)+\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier =sys.argv[1]\n",
    "    version = sys.argv[2]\n",
    "    file = sys.argv[3]\n",
    "       \n",
    "    if classifier == \"nb\" and version == \"u\":\n",
    "        predictL  = testNaiveBayes_B(file)\n",
    "    elif classifier == \"nb\" and version == \"n\":\n",
    "        predictL = testNaiveBayes_A(file)\n",
    "    elif classifier == \"lr\" and version == \"n\":\n",
    "        predictL = testNormLR_A(file)\n",
    "    elif classifier == \"lr\" and version == \"u\":\n",
    "         predictL = testUnNormLR_B(file)\n",
    "    else:\n",
    "        print(\"Kindly check your syntax or input the right cominations\")\n",
    "        \n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    results(classifier, version,predictL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
