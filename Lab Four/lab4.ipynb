{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pandas to handle the files.\n",
    "#First read the list file and converting them to a list of dataframes using \n",
    "#Add them all into one big frame using concat\n",
    "corpus=['amazon_cells_labelled.txt',\"imdb_labelled.txt\",\"yelp_labelled.txt\"]\n",
    "data = pd.concat(pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col= None, header = 0 )\n",
    "for file in corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalised form of NaiveBayes Classifier\n",
    "#Training\n",
    "def NaiveBayes_A():\n",
    "    #noramalisation\n",
    "    stop_words =set(stopwords.words(\"english\"))\n",
    "    \n",
    "    #In order to count the word count per text it is easier to use Term Frequency Inverse Document Frequency\n",
    "    #Tfid transforms text to feature vecors,\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, strip_accents ='ascii', stop_words = stop_words, lowercase=True)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= vectorizer.fit_transform(data.Text) #Converting the dataframes in the data into features.\n",
    "    \n",
    "    #splitting our data into training and test sets\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 35 , train_size =0.95, test_size =0.05)\n",
    "    \n",
    "    #Training the Classifier (MultinomialNB Normalised Classifier(MNBN Classifier))\n",
    "    MNBN_classifier = MultinomialNB()\n",
    "    model = MNBN_classifier.fit(x_train, y_train)\n",
    "   \n",
    "\n",
    "    return MNBN_classifier , vectorizer, model, x_test, y_test\n",
    "    \n",
    "#NaiveBayes_A()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NORMALISED NAIVE BAIYES CLASSIFIER\n",
    "def testNaiveBayes_A(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "    #Training on the normalised nb classifier\n",
    "    MNBN_classifier , vectorizer, model, x_test, y_test = NaiveBayes_A()\n",
    "    \n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "    \n",
    "   #Evaluating the model using the classification report function form sklearn\n",
    "\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" ,accuracy_score(y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier was evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    \n",
    "    return y\n",
    "#testNaiveBayes_A(\"yelp_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnNormalised form of NaiveBayes Classifier\n",
    "#Training\n",
    "def NaiveBayes_B():\n",
    "\n",
    "    #In order to count the word count per text it is easier to use Term Frequency Inverse Document Frequency\n",
    "    #Tfid transforms text to feature vecors,\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, strip_accents =None, lowercase=False)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= vectorizer.fit_transform(data.Text) #Converting the dataframes in the data into features.\n",
    "    \n",
    "    #splitting our data into training and test sets\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 35 , train_size =0.95, test_size =0.05)\n",
    "    \n",
    " #Training the Classifier (MultinomialNB Unormalised Classifier(MNBU Classifier))\n",
    "\n",
    "    MNBU_classifier = MultinomialNB()\n",
    "    model= MNBU_classifier.fit(x_train, y_train)\n",
    "   \n",
    "\n",
    "    return MNBU_classifier , vectorizer, model, x_test,y_test\n",
    "    \n",
    "#NaiveBayes_B()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRAINING THE UNNORMALISED NAIVE BAIYES CLASSIFIER\n",
    "def testNaiveBayes_B(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "      #Training on the unnormalised nb classifier\n",
    "    MNBU_classifier  , vectorizer, model, x_test, y_test = NaiveBayes_B()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "    \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" ,accuracy_score(y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    return y\n",
    "    \n",
    "#testNaiveBayes_B(\"yelp_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A NORMALISED LOGISTIC REGRESSION TRAIN FUNCTION.\n",
    "def normLR_A():\n",
    "    #noramalisation\n",
    "    stop_words =set(stopwords.words(\"english\"))\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, strip_accents ='ascii', stop_words = stop_words, lowercase=True)\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "     \n",
    "    y = data.Label\n",
    "    x=vectorizer.fit_transform(data.Text)# transfroming the data to features \n",
    "    \n",
    "    #Removing unnecessary punctuations\n",
    "    df['Text'] = df.Text.str.replace('[^\\w\\s]', '') \n",
    " \n",
    "    #Training the data\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 40, train_size =0.95, test_size =0.05)\n",
    "   \n",
    "    #Training the Classifier (Logistic Regression Normalised Classifier(LRN))\n",
    "    LRN_classifier = LogisticRegression()\n",
    "    model = LRN_classifier.fit(x_train, y_train)\n",
    "        \n",
    "    return LRN_classifier, vectorizer, model, x_test, y_test\n",
    "#normLR_A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NORMALISED LOGISTIC REGRESSION CLASSIFIER\n",
    "def testNormLR_A(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    \n",
    "      #Training on the normalised LR classifier\n",
    "    LRN_classifier , vectorizer, model, x_test, y_test = normLR_A()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "   \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" , accuracy_score (y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    return y\n",
    "    \n",
    "    \n",
    "#testNormLR_A(\"yelp_labelled.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AN UNNORMALISED  LOGISTIC REGRESSION TRAIN FUNCTION.\n",
    "def unNormLR_B():\n",
    "    \n",
    "    #making an unnormalised form of our classifier y removing stop words, and not performing any form of normalisation\n",
    "    UnNormalisedVectorizer = TfidfVectorizer(use_idf=False, strip_accents=None, lowercase=False )\n",
    "    \n",
    "    #Setting labels where 0 is negative and 1 is positive\n",
    "    y = data.Label\n",
    "    x= UnNormalisedVectorizer.fit_transform(data.Text)# transfroming the data to features \n",
    "    \n",
    "    #Training the data\n",
    "    x_train, x_test, y_train, y_test =train_test_split(x,y, random_state = 40, train_size =0.95, test_size =0.05)\n",
    "    \n",
    "    #Training the Classifier ( UnNormalised Logistic Regression Classifier)\n",
    "    UnNormalisedLr_classifier =LogisticRegression()\n",
    "    model = UnNormalisedLr_classifier.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    return UnNormalisedLr_classifier, UnNormalisedVectorizer, model, x_test, y_test\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE NORMALISED LOGISTIC REGRESSION CLASSIFIER\n",
    "def testUnNormLR_B(file):\n",
    "    #Reading of the file\n",
    "    df = pd.read_csv(file, sep='\\t', names=['Text','Label'], index_col=None, header =-1)\n",
    "    print(df)\n",
    "    \n",
    "      #Training on the normalised LR classifier\n",
    "        \n",
    "    UnNormalisedLr_classifier, vectorizer, model, x_test, y_test = unNormLR_B()\n",
    "    ##Setting labels where 0 is negative and 1 is positive\n",
    "    y = list(df.Label)\n",
    "    x=  df.Text\n",
    "    \n",
    "    #Evaluating the model using the classification report function form sklearn\n",
    "    predicted = model.predict(x_test)\n",
    "    print(\"Our Accuracy is: \" ,np.mean(predicted == y_test)*100) \n",
    "    \n",
    "    print(\" Accuracy is: \" , accuracy_score (y_test, predicted)*100) \n",
    "    \n",
    "    print(\" Below is how the classifier is evaluated: \\n\" ,classification_report(y_test, predicted))\n",
    "    return y\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(classifier, version, y):\n",
    "    file_name = open(\"results-\"+classifier+\"-\"+version+\".txt\", w)\n",
    "    file_name.write(\"y: \"+\"\\n\")\n",
    "    \n",
    "    for label in y:\n",
    "        file_name.write(str(label)+\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if__name__ == \"__main__\":\n",
    "    classifier =sys.argv[1]\n",
    "    version = sys.argv[2]\n",
    "    file = sys.argv[3]\n",
    "    \n",
    "    if classifier == \"nb\" and version == \"u\":\n",
    "        testNaiveBayes_B(file)\n",
    "    elif classifier == \"nb\" and version == \"n\":\n",
    "        testNaiveBayes_A(file)\n",
    "    elif classifier == \"lr\" and version == \"n\":\n",
    "        testNormLR_A(file)\n",
    "    elif classifier == \"lr\" and version == \"u\":\n",
    "        testUnNormLR_B(file)\n",
    "    else:\n",
    "        print(\"Kindly check your syntax or input the right cominations\")\n",
    "        \n",
    "        sys.exit()\n",
    "        \n",
    "    \n",
    "    results(classifier, version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
